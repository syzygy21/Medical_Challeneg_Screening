{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e79acb2d-e51e-472a-a9fa-faee81622364",
   "metadata": {},
   "source": [
    "Medical Question-Answering: Evaluation & Inference\n",
    "---------------------------------------------------\n",
    "This script performs two tasks:\n",
    "1. Evaluates multiple checkpoints of a fine-tuned Flan-T5 model on a test set.\n",
    "2. Demonstrates the modelâ€™s response quality on sample medical questions.\n",
    "\n",
    "Author: Navdeep  \n",
    "Last Modified: April 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9805e5e-6846-420c-ade3-c17d9d406b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ea68695cd7c4d8493dc36e0b604c943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1641 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing test loss for models using None samples...\n",
      "Using device: cuda\n",
      "Using all 1641 samples from test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:12<00:00, 16.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: 35074, Test Loss: 1.7212\n",
      "Using device: cuda\n",
      "Using all 1641 samples from test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:11<00:00, 17.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: 33228, Test Loss: 1.7225\n",
      "Using device: cuda\n",
      "Using all 1641 samples from test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206/206 [00:11<00:00, 17.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint: 25844, Test Loss: 1.7358\n",
      "\n",
      "Summary of Test Loss Results:\n",
      "==================================================\n",
      "Checkpoint           | Test Loss \n",
      "--------------------------------------------------\n",
      "35074                | 1.7212    \n",
      "33228                | 1.7225    \n",
      "25844                | 1.7358    \n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 1. LIBRARY IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # Fix for potential OpenMP conflict\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq\n",
    ")\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================================\n",
    "# 2. DATA LOADING AND PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "# Load and clean the medical Q&A dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Navdeep\\Documents\\ML_Challenge\\mle_screening_dataset.csv\")\n",
    "df[\"question\"] = df[\"question\"].str.strip()\n",
    "df[\"answer\"] = df[\"answer\"].fillna(\"\").str.strip()\n",
    "df = df.rename(columns={\"question\": \"input_text\", \"answer\": \"target_text\"})\n",
    "\n",
    "# Convert to HuggingFace Dataset and split into train/test\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "\n",
    "# Load tokenizer\n",
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define the preprocessing/tokenization function\n",
    "def preprocess_function(examples):\n",
    "    prefix = \"Answer the medical question: \"\n",
    "    inputs = [prefix + question for question in examples[\"input_text\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True)\n",
    "    labels = tokenizer(text_target=examples[\"target_text\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# Tokenize the test set\n",
    "tokenized_test = dataset[\"test\"].map(preprocess_function, batched=True)\n",
    "\n",
    "# ============================================================================\n",
    "# 3. EVALUATE MULTIPLE CHECKPOINTS\n",
    "# ============================================================================\n",
    "\n",
    "# Define the paths to the model checkpoints to be evaluated\n",
    "checkpoint_paths = [\n",
    "    r\"C:\\Users\\Navdeep\\Documents\\ML_Challenge\\flan-t5-medical-qa_3\\checkpoint-35074\",\n",
    "    r\"C:\\Users\\Navdeep\\Documents\\ML_Challenge\\flan-t5-medical-qa_3\\checkpoint-33228\",\n",
    "    r\"C:\\Users\\Navdeep\\Documents\\ML_Challenge\\flan-t5-medical-qa_3\\checkpoint-25844\"\n",
    "]\n",
    "\n",
    "def compute_loss(model_path, num_samples=None):\n",
    "    \"\"\"\n",
    "    Computes the average loss on the test set for a given model checkpoint.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to the checkpoint directory.\n",
    "        num_samples (int or None): Number of test samples to evaluate. If None, uses all.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (average_loss, checkpoint_name)\n",
    "    \"\"\"\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\").eval()\n",
    "    print(f\"\\nEvaluating checkpoint: {model_path}\")\n",
    "\n",
    "    # Optional subset selection\n",
    "    test_dataset = tokenized_test\n",
    "    if num_samples and num_samples < len(tokenized_test):\n",
    "        test_dataset = tokenized_test.select(range(num_samples))\n",
    "        print(f\"Using {num_samples} test samples\")\n",
    "    else:\n",
    "        print(f\"Using full test set: {len(test_dataset)} samples\")\n",
    "\n",
    "    # Setup data loader\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "    from torch.utils.data import DataLoader\n",
    "    test_dataloader = DataLoader(\n",
    "        test_dataset.remove_columns([\"input_text\", \"target_text\"]),\n",
    "        batch_size=8,\n",
    "        collate_fn=data_collator,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Compute average loss\n",
    "    total_loss, num_batches = 0.0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "            loss = model(**batch).loss\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    checkpoint_name = model_path.split(\"checkpoint-\")[-1]\n",
    "    return avg_loss, checkpoint_name\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting evaluation of model checkpoints...\\n\")\n",
    "    results = []\n",
    "\n",
    "    # Loop through each checkpoint and compute test loss\n",
    "    for path in checkpoint_paths:\n",
    "        loss, name = compute_loss(path)\n",
    "        results.append({\"checkpoint\": name, \"loss\": loss})\n",
    "        print(f\"âœ… Checkpoint {name} â†’ Test Loss: {loss:.4f}\")\n",
    "\n",
    "    # Display all results in a tabular format\n",
    "    print(\"\\nðŸ“Š Summary of Test Losses:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Checkpoint':<20} | {'Test Loss':<10}\")\n",
    "    print(\"-\" * 50)\n",
    "    for res in results:\n",
    "        print(f\"{res['checkpoint']:<20} | {res['loss']:<10.4f}\")\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cacbfcf4-cf05-4a1e-a5b0-0b82652510e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: What is hypertension and what blood pressure readings indicate this condition?\n",
      "Answer: Hypertension is a condition that affects the blood pressure of the body. It is caused by a change (mutation) in the X-linked gene, which is involved in the normal flow of blood to the body's bloodstream. This condition is inherited in an autosomal recessive pattern, which means both copies of the gene in each cell have mutations. The parents of an individual with hypertension typically have one copy of the mutated gene, but they typically do not show signs and symptoms of the condition.\n",
      "--------------------------------------------------\n",
      "Question: What are the main functions of the kidneys in the human body?\n",
      "Answer: Key Points - The kidneys are made up of many different organs, including the kidneys, tissues, and organs. - There are three main functions of kidneys in the body: - Kidneys are part of the body's immune system, which helps fight infection and protects the body from infection - It is important to maintain a healthy immune system and to prevent infections - Causes of kidney disease include - Chronic kidney disease - Hypertension - Decreased levels of calcium in the blood - High levels of potassium in the urine - Increased amounts of\n",
      "--------------------------------------------------\n",
      "Question: How does insulin work in controlling blood sugar levels?\n",
      "Answer: Insulin plays a role in controlling blood sugar levels. Insulin helps control the amount of sugar in your blood. This means that you can use it to control your blood sugar level. If you have diabetes, you may want to think about taking part in a blood glucose test. You can take part in an insulin test to find out if your blood glucose levels are too high or too low. For example, you might want to talk with your doctor if you think you may be at risk for diabetes.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 4. SAMPLE QUESTION-ANSWER INFERENCE\n",
    "# ============================================================================\n",
    "\n",
    "# Necessary imports\n",
    "import torch\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "def load_and_test_model(model_path, questions):\n",
    "    \"\"\"\n",
    "    Generates answers for a list of medical questions using a fine-tuned model.\n",
    "\n",
    "    Args:\n",
    "        model_path (str): Path to a saved model checkpoint.\n",
    "        questions (list): List of medical questions as strings.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping each question to the generated answer.\n",
    "    \"\"\"\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\").eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    results = {}\n",
    "\n",
    "    for question in questions:\n",
    "        # Prepare input\n",
    "        prefixed = \"Answer the medical question: \" + question\n",
    "        inputs = tokenizer(prefixed, return_tensors=\"pt\", max_length=512, truncation=True).to(\"cuda\")\n",
    "\n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            output_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_length=128,\n",
    "                num_beams=5,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                repetition_penalty=1.5\n",
    "            )\n",
    "        answer = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "        results[question] = answer\n",
    "\n",
    "        # Print Q&A\n",
    "        print(f\"ðŸ”¹ Question: {question}\")\n",
    "        print(f\"ðŸ”¸ Answer: {answer}\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example inference usage\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\nRunning example inference...\\n\")\n",
    "    example_model_path = r\"C:\\Users\\Navdeep\\Documents\\ML_Challenge\\flan-t5-medical-qa_3\\checkpoint-35074\"\n",
    "    example_questions = [\n",
    "        \"What is hypertension and what blood pressure readings indicate this condition?\",\n",
    "        \"What are the main functions of the kidneys in the human body?\",\n",
    "        \"How does insulin work in controlling blood sugar levels?\"\n",
    "    ]\n",
    "    load_and_test_model(example_model_path, example_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131f8775-a018-4b6d-b418-a2f84f32f91f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
